# Daily Sports Scores Pipeline

A **fully automated data pipeline** fetching, cleaning, and summarizing live MLB and NBA scores daily â€” built with Python, CLI tools, and structured logging.

---

## Project Overview

This project demonstrates a real-world Data Engineering pipeline from end-to-end:

- Fetches live MLB data from [MLB Stats API](https://statsapi.mlb.com/)
- Fetches live NBA data from [API-NBA via RapidAPI](https://rapidapi.com/api-sports/api/api-nba)
- Cleans and normalizes raw JSON data for easy consumption
- Generates daily summaries with real-time scores and game statuses
- Logs all steps for monitoring and debugging
- Can be scheduled via cron for daily automation
- Includes a Streamlit app (optional) to visualize daily sports summaries interactively

---

## Tech Stack & Tools

- Python 3.13+
- `requests` for API calls
- `logging` for structured logs
- `python-dotenv` for environment variable management
- Bash shell scripting (`run_pipeline.sh`)
- Cron job automation for scheduling
- Streamlit (optional) for UI visualization

---

## Project Structure

```

daily-pipeline/
â”œâ”€â”€ app.py                    # Streamlit app for summary visualization
â”œâ”€â”€ fetch\_data/
â”‚   â”œâ”€â”€ fetch\_mlb.py          # Fetch MLB scores script
â”‚   â””â”€â”€ fetch\_nba.py          # Fetch NBA scores script
â”œâ”€â”€ format\_data/
â”‚   â”œâ”€â”€ clean\_mlb.py          # Clean MLB raw data script
â”‚   â””â”€â”€ clean\_nba.py          # Clean NBA raw data script
â”œâ”€â”€ logs/                     # Log files generated during runs
â”œâ”€â”€ raw\_data/
â”‚   â”œâ”€â”€ raw\_mlb.json          # Raw MLB JSON data
â”‚   â””â”€â”€ raw\_nba.json          # Raw NBA JSON data
â”œâ”€â”€ run\_pipeline.sh           # Bash script to run the whole pipeline
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ logger.py             # Centralized logging setup
â”œâ”€â”€ venv/                     # Python virtual environment
â”œâ”€â”€ requirements.txt          # Project dependencies
â”œâ”€â”€ README.md                 # This file
â””â”€â”€ load\_env.py               # Loads environment variables

````

---

## Setup & Installation

1. Clone the repo:
   ```bash
   git clone https://github.com/joanovallesr/daily-pipeline.git
   cd daily-pipeline
````

2. Create and activate virtual environment:

   ```bash
   python3 -m venv venv
   source venv/bin/activate
   ```

3. Install dependencies:

   ```bash
   pip install -r requirements.txt
   ```

4. Create a `.env` file and add your RapidAPI key:

   ```
   RAPIDAPI_KEY=your_rapidapi_key_here
   ```

---

## ðŸƒâ€â™‚ï¸ Running the Pipeline

* Run manually:

  ```bash
  ./run_pipeline.sh
  ```

* Run individual scripts:

  ```bash
  python3 fetch_data/fetch_mlb.py
  python3 format_data/clean_mlb.py
  python3 fetch_data/fetch_nba.py
  python3 format_data/clean_nba.py
  python3 output/daily_summary.py
  ```

* Run Streamlit app:

  ```bash
  streamlit run app.py
  ```

---

## Scheduling with Cron

Set up a cron job to run the pipeline daily at 8 AM:

```bash
crontab -e
```

Add the line:

```
0 8 * * * cd /path/to/daily-pipeline && ./run_pipeline.sh >> logs/cron.log 2>&1
```

---

## How It Works

1. **Fetching:** Scripts call external APIs to retrieve raw JSON game data.
2. **Cleaning:** Clean scripts parse and extract relevant data, saving clean JSON.
3. **Summary:** Summary script reads clean data and formats a human-readable daily sports report.
4. **Logging:** All steps logged to console and rotating log files for traceability.
5. **Visualization:** Streamlit app displays the latest daily summary interactively.

---

## Contributing

Contributions welcome! Feel free to open issues or pull requests.

---

## License

MIT License Â© 2025 Joan Ovalles

---

## Author

Joan Ovalles | [GitHub](https://github.com/joanovallesr) | [LinkedIn](https://linkedin.com/in/joanovallesr)
